{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1fa1773-a9c2-4dd8-a551-77ac7c03b179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\gamer\\Desktop\\AktienPrognose\n",
      "pandas 2.3.1 | numpy 2.1.3\n",
      "OK: yfinance\n",
      "OK: pandas_datareader\n",
      "OK: pyarrow\n",
      "FS write check: OK\n"
     ]
    }
   ],
   "source": [
    "# Setup: Top-cell setup keeps the notebook reproducible and idempotent across runs.\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path  # Pathlib paths are safer/cross-platform versus raw strings.\n",
    "import sys  # We'll adjust sys.path if needed to import local packages from 'src'.\n",
    "import importlib  # Lightweight smoke-tests for optional/runtime dependencies.\n",
    "import warnings  # Downstream libs can be noisy thus suppress to keep output readable.\n",
    "import logging  # Logging > prints for structured status.\n",
    "from typing import Iterable  # For type hints on small helpers.\n",
    "\n",
    "import yaml  # Config-driven pipeline.\n",
    "import pandas as pd  # WHY: Core data structure for time series and IO.\n",
    "import numpy as np  # WHY: Ensure NumPy is available; some ops rely on it.\n",
    "\n",
    "# Minimal, readable logging configuration for interactive work.\n",
    "warnings.filterwarnings(\"ignore\")  # Hide known-but-noncritical warnings in data pulls.\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
    "logger = logging.getLogger(\"setup\")\n",
    "\n",
    "def find_project_root(start: Path) -> Path:\n",
    "    start = start.resolve()\n",
    "    for p in [start, *start.parents]:\n",
    "        if (p/\"config\").exists() and (p/\"src\").exists():\n",
    "            return p\n",
    "    raise AssertionError(\"Project folders missing: expected 'config' and 'src' somewhere above the notebook.\")\n",
    "\n",
    "ROOT = find_project_root(Path.cwd())\n",
    "assert (ROOT / \"config\").exists() and (ROOT / \"src\").exists(), \"Project folders missing.\"\n",
    "print(\"Project root:\", ROOT)  # Quick sanity check for cwd-based path logic.\n",
    "\n",
    "# Ensure standard artifact locations exist (clear separation of outputs).\n",
    "ARTIFACT_DIRS: tuple[str, ...] = (\n",
    "    \"artifacts/data\",\n",
    "    \"artifacts/models\",\n",
    "    \"artifacts/forecasts\",\n",
    "    \"artifacts/metrics\",\n",
    "    \"artifacts/reports\",\n",
    "    \"artifacts/tmp\",\n",
    ")\n",
    "for rel in ARTIFACT_DIRS:\n",
    "    (ROOT / rel).mkdir(parents=True, exist_ok=True)  # Idempotent directory creation.\n",
    "\n",
    "# Core libs test.\n",
    "print(\"pandas\", pd.__version__, \"| numpy\", np.__version__)\n",
    "\n",
    "# Critical dependencies we rely on later.\n",
    "def _smoke_imports(pkgs: Iterable[str]) -> None:\n",
    "    \"\"\"Import packages to fail fast if a dependency is missing.\n",
    "    Args: pkgs: Iterable of package names to import.\n",
    "    Raises: RuntimeError: If any import fails.\"\"\"\n",
    "\n",
    "    # Prefer early, explicit dependency failures.\n",
    "    for pkg in pkgs:\n",
    "        try:\n",
    "            importlib.import_module(pkg)\n",
    "            print(f\"OK: {pkg}\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\n",
    "                f\"Missing or broken dependency: {pkg}. Install it and retry.\"\n",
    "            ) from e\n",
    "\n",
    "_smoke_imports([\"yfinance\", \"pandas_datareader\", \"pyarrow\"])\n",
    "\n",
    "# Filesystem writability.\n",
    "tmpfile = ROOT / \"artifacts\" / \"tmp\" / \"write_check.txt\"\n",
    "try:\n",
    "    tmpfile.write_text(\"ok\", encoding=\"utf-8\")\n",
    "    print(\"FS write check: OK\")\n",
    "finally:\n",
    "    if tmpfile.exists():\n",
    "        tmpfile.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe24a322-6008-4070-ab5a-a0de87bff993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "from pprint import pprint as pp \n",
    "\n",
    "def _load_config(cfg_path: Path) -> dict:\n",
    "    \"\"\"Load YAML config with crisp error messages.\n",
    "    Args: cfg_path: Path to YAML configuration.\n",
    "    Returns: Dict with configuration data (empty dict if file is blank).\n",
    "    Raises:\n",
    "        FileNotFoundError: If the path does not exist.\n",
    "        RuntimeError: If YAML parsing fails.\"\"\"\n",
    "\n",
    "    # Centralized loader makes error handling uniform and testable.\n",
    "    if not cfg_path.exists():\n",
    "        raise FileNotFoundError(f\"Config not found: {cfg_path}\")\n",
    "    try:\n",
    "        with cfg_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "            return yaml.safe_load(f) or {}\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to parse YAML: {cfg_path}\") from e\n",
    "\n",
    "\n",
    "def _require_keys(obj: dict, keys: Iterable[str], ctx: str) -> None:\n",
    "    \"\"\"Fail fast if required keys are missing to avoid cryptic errors later.\n",
    "    Args:\n",
    "        obj: Mapping to validate.\n",
    "        keys: Required key names.\n",
    "    Raises: KeyError: If any key is missing.\"\"\"\n",
    "\n",
    "    # Guardrails make subsequent code simpler and reduce nested conditionals.\n",
    "    for k in keys:\n",
    "        if k not in obj:\n",
    "            raise KeyError(f\"Missing key '{k}' in {ctx}\")\n",
    "\n",
    "\n",
    "def _assert_guardrail_dates(ds_cfg: dict) -> None:\n",
    "    \"\"\"Enforce expected date window for this project.\n",
    "    Args: ds_cfg: The 'dataset' sub-config.\n",
    "    Raises: AssertionError: If dates differ from the guardrails.\"\"\"\n",
    "\n",
    "    # This project expects a fixed backtest window.\n",
    "    print(\"Config window:\", ds_cfg[\"start_date\"], \"→\", ds_cfg[\"end_date\"])\n",
    "    assert ds_cfg[\"start_date\"] == \"2008-01-01\"\n",
    "    assert ds_cfg[\"end_date\"] == \"2025-06-30\"\n",
    "    print(\"Guardrails OK (2008-01-01 .. 2025-06-30)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "705284be-f1a1-40cb-9e32-c526c4cfd673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config window: 2008-01-01 → 2025-06-30\n",
      "Guardrails OK (2008-01-01 .. 2025-06-30)\n",
      "{'end_date': '2025-06-30',\n",
      " 'equities': [{'agg': 'last',\n",
      "               'name': 'SP500',\n",
      "               'source': 'yahoo',\n",
      "               'symbol': '^GSPC'}],\n",
      " 'macro': [{'agg': 'last',\n",
      "            'name': 'FedFundsRate',\n",
      "            'series_id': 'FEDFUNDS',\n",
      "            'source': 'fred'},\n",
      "           {'agg': 'last',\n",
      "            'name': 'CPI',\n",
      "            'series_id': 'CPIAUCSL',\n",
      "            'source': 'fred'},\n",
      "           {'agg': 'last',\n",
      "            'name': 'UnemploymentRate',\n",
      "            'series_id': 'UNRATE',\n",
      "            'source': 'fred'},\n",
      "           {'agg': 'last',\n",
      "            'name': 'VIX',\n",
      "            'series_id': 'VIXCLS',\n",
      "            'source': 'fred'},\n",
      "           {'agg': 'mean',\n",
      "            'name': 'EPU_US',\n",
      "            'series_id': 'USEPUINDXM',\n",
      "            'source': 'fred'},\n",
      "           {'agg': 'mean',\n",
      "            'name': 'FSI',\n",
      "            'series_id': 'STLFSI4',\n",
      "            'source': 'fred'},\n",
      "           {'agg': 'mean',\n",
      "            'fallback': {'agg': 'mean', 'source': 'yahoo', 'symbol': 'GLD'},\n",
      "            'name': 'Gold_USD_oz',\n",
      "            'series_id': 'GOLDAMGBD228NLBM',\n",
      "            'source': 'fred'},\n",
      "           {'agg': 'mean',\n",
      "            'name': 'WTI_Spot',\n",
      "            'series_id': 'MCOILWTICO',\n",
      "            'source': 'fred'},\n",
      "           {'agg': 'last',\n",
      "            'name': 'USD_per_EUR',\n",
      "            'series_id': 'DEXUSEU',\n",
      "            'source': 'fred'}],\n",
      " 'start_date': '2008-01-01'}\n"
     ]
    }
   ],
   "source": [
    "# Config\n",
    "CFG_PATH: Path = ROOT / \"config\" / \"data_config.yaml\"\n",
    "cfg_data: dict = _load_config(CFG_PATH)\n",
    "\n",
    "# Minimal schema checks\n",
    "_require_keys(cfg_data, [\"dataset\"], \"config/data_config.yaml\")\n",
    "_require_keys(cfg_data[\"dataset\"], [\"start_date\", \"end_date\"], \"config.dataset\")\n",
    "\n",
    "# Show/validate the configured window and sources.\n",
    "_assert_guardrail_dates(cfg_data[\"dataset\"])\n",
    "pp(cfg_data.get(\"dataset\", {}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b735ed9-5aac-4ca8-b78f-785b2e49a7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data present: C:\\Users\\gamer\\Desktop\\AktienPrognose\\artifacts\\data\\raw_data.parquet\n"
     ]
    }
   ],
   "source": [
    "# Download: Download only if the unified raw parquet is missing; otherwise keep things fast and reproducible.\n",
    "RAW_PATH: Path = ROOT / \"artifacts\" / \"data\" / \"raw_data.parquet\"\n",
    "\n",
    "if not RAW_PATH.exists():\n",
    "    print(\"No raw_data.parquet found → starting download...\")\n",
    "    # Ensure 'src' is importable.\n",
    "    src_path = str(ROOT)\n",
    "    if src_path not in sys.path:  # Avoid duplicating sys.path entries across reruns.\n",
    "        sys.path.append(src_path)\n",
    "\n",
    "    try:\n",
    "        from src.data.download_data import download_all_data\n",
    "    except Exception as e:\n",
    "        raise ImportError(\n",
    "            \"Cannot import 'download_all_data' from src.data.download_data. \"\n",
    "            \"Verify that 'src' is present and importable.\"\n",
    "        ) from e\n",
    "\n",
    "    try:\n",
    "        download_all_data(config_path=CFG_PATH, out_path=RAW_PATH)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Data download failed: {e}\") from e\n",
    "else:\n",
    "    print(\"Raw data present:\", RAW_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "490581be-a97f-4721-947d-679385683dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (210, 10) | Range: 2008-01-31 → 2025-06-30\n",
      "Example columns: ['SP500', 'FedFundsRate', 'CPI', 'UnemploymentRate', 'VIX', 'EPU_US', 'FSI', 'Gold_USD_oz', 'WTI_Spot', 'USD_per_EUR']\n",
      "Top-8 missing rates:\n",
      " EPU_US              0.014286\n",
      "SP500               0.000000\n",
      "FedFundsRate        0.000000\n",
      "CPI                 0.000000\n",
      "UnemploymentRate    0.000000\n",
      "VIX                 0.000000\n",
      "FSI                 0.000000\n",
      "Gold_USD_oz         0.000000\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SP500</th>\n",
       "      <th>FedFundsRate</th>\n",
       "      <th>CPI</th>\n",
       "      <th>UnemploymentRate</th>\n",
       "      <th>VIX</th>\n",
       "      <th>EPU_US</th>\n",
       "      <th>FSI</th>\n",
       "      <th>Gold_USD_oz</th>\n",
       "      <th>WTI_Spot</th>\n",
       "      <th>USD_per_EUR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-04-30</th>\n",
       "      <td>5569.060059</td>\n",
       "      <td>4.33</td>\n",
       "      <td>320.321</td>\n",
       "      <td>4.2</td>\n",
       "      <td>24.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.045375</td>\n",
       "      <td>296.956668</td>\n",
       "      <td>63.54</td>\n",
       "      <td>1.1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-31</th>\n",
       "      <td>5911.689941</td>\n",
       "      <td>4.33</td>\n",
       "      <td>320.580</td>\n",
       "      <td>4.2</td>\n",
       "      <td>18.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.550700</td>\n",
       "      <td>302.891427</td>\n",
       "      <td>62.17</td>\n",
       "      <td>1.1347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-30</th>\n",
       "      <td>6173.069824</td>\n",
       "      <td>4.33</td>\n",
       "      <td>321.500</td>\n",
       "      <td>4.1</td>\n",
       "      <td>16.73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.737750</td>\n",
       "      <td>309.088421</td>\n",
       "      <td>68.17</td>\n",
       "      <td>1.1770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  SP500  FedFundsRate      CPI  UnemploymentRate    VIX  \\\n",
       "2025-04-30  5569.060059          4.33  320.321               4.2  24.70   \n",
       "2025-05-31  5911.689941          4.33  320.580               4.2  18.57   \n",
       "2025-06-30  6173.069824          4.33  321.500               4.1  16.73   \n",
       "\n",
       "            EPU_US       FSI  Gold_USD_oz  WTI_Spot  USD_per_EUR  \n",
       "2025-04-30     NaN  0.045375   296.956668     63.54       1.1349  \n",
       "2025-05-31     NaN -0.550700   302.891427     62.17       1.1347  \n",
       "2025-06-30     NaN -0.737750   309.088421     68.17       1.1770  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Integrity: Structural checks catch common leakage/index issues before modeling.\n",
    "df = pd.read_parquet(RAW_PATH)\n",
    "\n",
    "# Quick overview to anchor expectations.\n",
    "min_idx, max_idx = str(df.index.min())[:10], str(df.index.max())[:10]\n",
    "print(\"Shape:\", df.shape, \"| Range:\", min_idx, \"→\", max_idx)\n",
    "\n",
    "# Hard bounds to confirm leakage guard.\n",
    "assert isinstance(df.index, pd.DatetimeIndex), \"Index must be DatetimeIndex.\"  # Time ops assume DatetimeIndex.\n",
    "assert min_idx >= \"2008-01-01\", \"Index starts before allowed window.\"  # Prevent look-behind leakage.\n",
    "assert max_idx <= \"2025-06-30\", \"Index extends beyond allowed window.\"  # Prevent look-ahead leakage.\n",
    "\n",
    "# Ensure deterministic ordering for reproducible downstream splits.\n",
    "if not df.index.is_monotonic_increasing:\n",
    "    df = df.sort_index()\n",
    "\n",
    "# Quick visibility\n",
    "print(\"Example columns:\", list(df.columns)[:10])\n",
    "na_rate = df.isna().mean().sort_values(ascending=False).head(8)\n",
    "print(\"Top-8 missing rates:\\n\", na_rate)\n",
    "df.tail(3)  # Display last few rows to quickly spot month-end alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95058c5e-e599-4284-80a8-36d666c674bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Project Checklist**\n",
       "- [x] Data loaded (`artifacts/data/raw_data.parquet`)\n",
       "- [ ] Raw audit (`01_data_raw_audit.ipynb`)\n",
       "- [ ] Build features (`02_build_features_monthly.ipynb`)\n",
       "- [ ] EDA (`03_eda.ipynb`)\n",
       "- [ ] Baselines (`10_train_eval_baselines.ipynb`)\n",
       "- [ ] Linear models (`20_train_eval_linear.ipynb`)\n",
       "- [ ] ARIMA (`21_train_eval_arima.ipynb`)\n",
       "- [ ] Random Forest (`22_train_eval_random_forest.ipynb`)\n",
       "- [ ] LSTM (`23_train_eval_lstm.ipynb`)\n",
       "- [ ] Ensembles (`90_ensembles.ipynb`)\n",
       "- [ ] Final report (`99_report_reproducibility.ipynb`)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Results:\n",
    "from IPython.display import Markdown, display\n",
    "display(Markdown(\"\"\"\n",
    "**Project Checklist**\n",
    "- [x] Data loaded (`artifacts/data/raw_data.parquet`)\n",
    "- [ ] Raw audit (`01_data_raw_audit.ipynb`)\n",
    "- [ ] Build features (`02_build_features_monthly.ipynb`)\n",
    "- [ ] EDA (`03_eda.ipynb`)\n",
    "- [ ] Baselines (`10_train_eval_baselines.ipynb`)\n",
    "- [ ] Linear models (`20_train_eval_linear.ipynb`)\n",
    "- [ ] ARIMA (`21_train_eval_arima.ipynb`)\n",
    "- [ ] Random Forest (`22_train_eval_random_forest.ipynb`)\n",
    "- [ ] LSTM (`23_train_eval_lstm.ipynb`)\n",
    "- [ ] Ensembles (`90_ensembles.ipynb`)\n",
    "- [ ] Final report (`99_report_reproducibility.ipynb`)\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30b2563-e629-4849-ba2e-3ac4b4edcbfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
